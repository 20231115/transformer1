{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a070c5",
   "metadata": {},
   "source": [
    "# 使用 Transformer 实现中文文本摘要\n",
    "本笔记演示如何使用 Hugging Face Transformers 的中文摘要模型（Pegasus）进行：\n",
    "- 单条文本摘要\n",
    "- 批量文本摘要\n",
    "并提供常用参数（max_length/min_length/do_sample）与 GPU 自动选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选：安装/升级依赖（首次使用或版本较旧时执行）\n",
    "%pip install -q --upgrade transformers sentencepiece accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb42e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "# 选择较小、下载更快的中文摘要模型；如需更强效果可换 523M 版本\n",
    "model_name = \"IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\"  # 或 \"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\"\n",
    "\n",
    "# 强制使用 CUDA\n",
    "assert torch.cuda.is_available(), \"未检测到 CUDA，请在具有 GPU 的环境中运行或安装支持 CUDA 的 PyTorch。\"\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, trust_remote_code=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True).to(\"cuda\")\n",
    "\n",
    "device = 0  # 强制使用第 0 块 GPU\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单条中文文本摘要示例\n",
    "text = (\n",
    "    \"人工智能（Artificial Intelligence，缩写为 AI）是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新技术科学。\"\n",
    "    \"自 2012 年深度学习兴起以来，语音识别、计算机视觉、自然语言处理等领域取得了突破性进展。\"\n",
    "    \"近年来，大语言模型（LLM）在通用文本理解与生成能力上表现突出，推动了搜索、问答、写作辅助等应用的发展。\"\n",
    ")\n",
    "\n",
    "summary = summarizer(\n",
    "    text, max_length=128, min_length=20, do_sample=False\n",
    ")[0][\"summary_text\"]\n",
    "print(\"摘要:\\n\", summary)\n",
    "\n",
    "# 批量摘要（可选）\n",
    "texts = [\n",
    "    \"特斯拉宣布在上海建设新的储能超级工厂，生产其超大型商业储能产品 Megapack，预计年产量达一万台。此次投资将进一步完善特斯拉在中国的产业布局。\",\n",
    "    \"我国将加快推进算力基础设施建设，完善东数西算等工程布局，促进算力资源高效互联，满足 AI 训练与推理的巨大需求。\",\n",
    "]\n",
    "summaries = summarizer(texts, max_length=128, min_length=15, do_sample=False)\n",
    "print(\"\\n批量摘要：\")\n",
    "for i, r in enumerate(summaries):\n",
    "    print(f\"[{i}]\", r[\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57429434",
   "metadata": {},
   "source": [
    "# 从零实现 Transformer 翻译（含多头自注意力、FFN、残差+LayerNorm、位置编码）\n",
    "本节将在不依赖高层封装的情况下，用 PyTorch 实现一个最小可运行的 Transformer，并在一个玩具中英平行语料上训练与测试。\n",
    "注意：这是教学/演示规模（小模型+小数据），目的是跑通流程与理解结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "209d12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 强制使用 CUDA\n",
    "assert torch.cuda.is_available(), \"未检测到 CUDA，请在具有 GPU 的环境中运行或安装支持 CUDA 的 PyTorch。\"\n",
    "torch.cuda.set_device(0)\n",
    "device_torch = torch.device(\"cuda\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "d_model = 128\n",
    "n_head = 4\n",
    "d_ff = 256\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "max_len = 64\n",
    "batch_size = 8\n",
    "num_epochs = 30\n",
    "lr = 3e-4\n",
    "\n",
    "PAD, BOS, EOS, UNK = 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a9c85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):  # x: (B, T, C)\n",
    "        T = x.size(1)\n",
    "        x = x + self.pe[:T, :].unsqueeze(0)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = d_model // n_head\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, q, k, v, attn_mask: torch.Tensor = None):\n",
    "        B, Tq, C = q.shape\n",
    "        Tk = k.size(1)\n",
    "        H, D = self.n_head, self.head_dim\n",
    "        q = self.w_q(q).view(B, Tq, H, D).permute(0, 2, 1, 3)  # (B,H,Tq,D)\n",
    "        k = self.w_k(k).view(B, Tk, H, D).permute(0, 2, 1, 3)  # (B,H,Tk,D)\n",
    "        v = self.w_v(v).view(B, Tk, H, D).permute(0, 2, 1, 3)  # (B,H,Tk,D)\n",
    "        scores = (q @ k.transpose(-2, -1)) / math.sqrt(D)  # (B,H,Tq,Tk)\n",
    "        if attn_mask is not None:\n",
    "            # attn_mask: broadcastable to (B, H, Tq, Tk); 1 for keep, 0 for mask\n",
    "            scores = scores.masked_fill(attn_mask == 0, float('-inf'))\n",
    "        attn = self.softmax(scores)\n",
    "        attn = self.dropout(attn)\n",
    "        context = attn @ v  # (B,H,Tq,D)\n",
    "        context = context.permute(0, 2, 1, 3).contiguous().view(B, Tq, C)  # (B,Tq,C)\n",
    "        out = self.w_o(context)\n",
    "        return out\n",
    "\n",
    "class PositionwiseFFN(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.GELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(self.act(self.fc1(x))))\n",
    "\n",
    "class ResidualAddNorm(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, sublayer_out):\n",
    "        return self.norm(x + self.dropout(sublayer_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e07888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_head, dropout)\n",
    "        self.ffn = PositionwiseFFN(d_model, d_ff, dropout)\n",
    "        self.norm1 = ResidualAddNorm(d_model, dropout)\n",
    "        self.norm2 = ResidualAddNorm(d_model, dropout)\n",
    "    \n",
    "    def forward(self, x, src_mask=None):  # x: (B, S, C)\n",
    "        x2 = self.self_attn(x, x, x, attn_mask=src_mask)\n",
    "        x = self.norm1(x, x2)\n",
    "        x2 = self.ffn(x)\n",
    "        x = self.norm2(x, x2)\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_head, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, n_head, dropout)\n",
    "        self.ffn = PositionwiseFFN(d_model, d_ff, dropout)\n",
    "        self.norm1 = ResidualAddNorm(d_model, dropout)\n",
    "        self.norm2 = ResidualAddNorm(d_model, dropout)\n",
    "        self.norm3 = ResidualAddNorm(d_model, dropout)\n",
    "    \n",
    "    def forward(self, y, memory, tgt_mask=None, memory_mask=None):  # y:(B,T,C)\n",
    "        y2 = self.self_attn(y, y, y, attn_mask=tgt_mask)\n",
    "        y = self.norm1(y, y2)\n",
    "        y2 = self.cross_attn(y, memory, memory, attn_mask=memory_mask)\n",
    "        y = self.norm2(y, y2)\n",
    "        y2 = self.ffn(y)\n",
    "        y = self.norm3(y, y2)\n",
    "        return y\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_head, d_ff, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=PAD)\n",
    "        self.pos = PositionalEncoding(d_model, max_len, dropout)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_head, d_ff, dropout) for _ in range(num_layers)])\n",
    "    \n",
    "    def forward(self, src, src_mask=None):  # src:(B,S)\n",
    "        x = self.emb(src) * math.sqrt(self.emb.embedding_dim)\n",
    "        x = self.pos(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_head, d_ff, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=PAD)\n",
    "        self.pos = PositionalEncoding(d_model, max_len, dropout)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_head, d_ff, dropout) for _ in range(num_layers)])\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):  # tgt:(B,T)\n",
    "        y = self.emb(tgt) * math.sqrt(self.emb.embedding_dim)\n",
    "        y = self.pos(y)\n",
    "        for layer in self.layers:\n",
    "            y = layer(y, memory, tgt_mask, memory_mask)\n",
    "        return y\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model, n_head, d_ff, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, n_head, d_ff, num_layers, dropout)\n",
    "        self.decoder = Decoder(tgt_vocab, d_model, n_head, d_ff, num_layers, dropout)\n",
    "        self.generator = nn.Linear(d_model, tgt_vocab)\n",
    "    \n",
    "    def forward(self, src, tgt_inp, src_mask=None, tgt_mask=None, memory_mask=None):\n",
    "        memory = self.encoder(src, src_mask)  # (B,S,C)\n",
    "        out = self.decoder(tgt_inp, memory, tgt_mask, memory_mask)  # (B,T,C)\n",
    "        logits = self.generator(out)  # (B,T,V)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f58cdf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单分词与词表（英：按空格；中：按字符）\n",
    "def tokenize_en(s: str) -> List[str]:\n",
    "    return s.lower().strip().split()\n",
    "def tokenize_zh(s: str) -> List[str]:\n",
    "    return list(s.strip())  # 字符级，适合演示\n",
    "\n",
    "\n",
    "\n",
    "def build_vocab(token_lists: List[List[str]], min_freq: int = 1):\n",
    "    from collections import Counter\n",
    "    counter = Counter()\n",
    "    for tokens in token_lists:\n",
    "        counter.update(tokens)\n",
    "    itos = [\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"]\n",
    "    for tok, freq in counter.items():\n",
    "        if freq >= min_freq and tok not in itos:\n",
    "            itos.append(tok)\n",
    "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
    "    return stoi, itos\n",
    "\n",
    "def encode(tokens: List[str], stoi: dict, add_bos: bool, add_eos: bool, max_len: int):\n",
    "    ids = []\n",
    "    if add_bos:\n",
    "        ids.append(BOS)\n",
    "    for t in tokens:\n",
    "        ids.append(stoi.get(t, UNK))\n",
    "        if len(ids) >= max_len - (1 if add_eos else 0):\n",
    "            break\n",
    "    if add_eos:\n",
    "        ids.append(EOS)\n",
    "    return ids\n",
    "\n",
    "def pad_to_len(ids: List[int], max_len: int, pad_id: int = PAD):\n",
    "    return ids + [pad_id] * (max_len - len(ids))\n",
    "\n",
    "def decode(ids: List[int], itos: List[str]):\n",
    "    toks = []\n",
    "    for i in ids:\n",
    "        if i in (PAD, BOS, EOS):\n",
    "            continue\n",
    "        toks.append(itos[i] if i < len(itos) else \"<unk>\")\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5148024d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已从 d:\\xry\\yanjiusheng\\1\\DAMOXING\\lab1\\data\\test.csv 读取 8549 对句子，列: ('en', 'zh')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17579, 3003, 8549)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从 data/test.csv 读取并行语料（英->中），自动识别列名\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = Path.cwd() / \"data\"\n",
    "csv_path = data_dir / \"test.csv\"\n",
    "\n",
    "def load_pairs_from_csv(p: Path):\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"未找到数据文件: {p}\")\n",
    "    df = pd.read_csv(p, encoding=\"utf-8\", dtype=str)  # 读为字符串，避免 NaN\n",
    "    # 统一列名为小写，便于匹配\n",
    "    df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "    candidates = [\n",
    "        (\"en\", \"zh\"),\n",
    "        (\"english\", \"chinese\"),\n",
    "        (\"source\", \"target\"),\n",
    "        (\"src\", \"tgt\"),\n",
    "        (\"text_en\", \"text_zh\"),\n",
    "        (\"eng\", \"chn\"),\n",
    "    ]\n",
    "    col_en = col_zh = None\n",
    "    for a, b in candidates:\n",
    "        if a in df.columns and b in df.columns:\n",
    "            col_en, col_zh = a, b\n",
    "            break\n",
    "    if col_en is None or col_zh is None:\n",
    "        if len(df.columns) >= 2:\n",
    "            col_en, col_zh = df.columns[:2]\n",
    "            print(f\"未匹配到常见列名，默认使用前两列：{col_en}, {col_zh}\")\n",
    "        else:\n",
    "            raise ValueError(\"CSV 至少需要两列（英文、中文）\")\n",
    "    en_series = df[col_en].fillna(\"\").astype(str).str.strip()\n",
    "    zh_series = df[col_zh].fillna(\"\").astype(str).str.strip()\n",
    "    mask = (en_series != \"\") & (zh_series != \"\")\n",
    "    en_list = en_series[mask].tolist()\n",
    "    zh_list = zh_series[mask].tolist()\n",
    "    return list(zip(en_list, zh_list)), (col_en, col_zh), int(mask.sum())\n",
    "\n",
    "pairs, used_cols, n_rows = load_pairs_from_csv(csv_path)\n",
    "print(f\"已从 {csv_path} 读取 {n_rows} 对句子，列: {used_cols}\")\n",
    "\n",
    "# 构建词表\n",
    "src_tokens_list = [tokenize_en(s) for s, _ in pairs]\n",
    "tgt_tokens_list = [tokenize_zh(t) for _, t in pairs]\n",
    "src_stoi, src_itos = build_vocab(src_tokens_list)\n",
    "tgt_stoi, tgt_itos = build_vocab(tgt_tokens_list)\n",
    "\n",
    "src_vocab_size = len(src_itos)\n",
    "tgt_vocab_size = len(tgt_itos)\n",
    "src_vocab_size, tgt_vocab_size, len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "710bcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批处理与掩码\n",
    "def make_batch(pairs: List[Tuple[str, str]], batch_size: int, shuffle: bool = True):\n",
    "    idxs = list(range(len(pairs)))\n",
    "    if shuffle:\n",
    "        random.shuffle(idxs)\n",
    "    for i in range(0, len(idxs), batch_size):\n",
    "        b = [pairs[j] for j in idxs[i:i+batch_size]]\n",
    "        src_batch, tgt_inp_batch, tgt_out_batch = [], [], []\n",
    "        for s, t in b:\n",
    "            src_ids = encode(tokenize_en(s), src_stoi, add_bos=False, add_eos=True, max_len=max_len)\n",
    "            tgt_ids = encode(tokenize_zh(t), tgt_stoi, add_bos=True, add_eos=True, max_len=max_len)\n",
    "            # teacher forcing: 输入为 <bos> y1 ... y_{n-1}，输出为 y1 ... y_n <eos>\n",
    "            tgt_inp = tgt_ids[:-1]\n",
    "            tgt_out = tgt_ids[1:]\n",
    "            src_batch.append(pad_to_len(src_ids, max_len))\n",
    "            tgt_inp_batch.append(pad_to_len(tgt_inp, max_len))\n",
    "            tgt_out_batch.append(pad_to_len(tgt_out, max_len))\n",
    "        yield (\n",
    "            torch.tensor(src_batch, dtype=torch.long, device=device_torch),\n",
    "            torch.tensor(tgt_inp_batch, dtype=torch.long, device=device_torch),\n",
    "            torch.tensor(tgt_out_batch, dtype=torch.long, device=device_torch),\n",
    "        )\n",
    "\n",
    "def subsequent_mask(sz: int):\n",
    "    # (1, 1, T, T) 上三角为 -inf 或 0 的布尔版，这里用 1/0 表达 keep/mask\n",
    "    mask = torch.tril(torch.ones((sz, sz), dtype=torch.uint8, device=device_torch))\n",
    "    return mask.view(1, 1, sz, sz)\n",
    "\n",
    "def padding_mask(batch_ids: torch.Tensor, pad_id: int = PAD):\n",
    "    # (B, T) -> (B, 1, 1, T) 1/0\n",
    "    mask = (batch_ids != pad_id).unsqueeze(1).unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "def combine_masks(*masks):\n",
    "    # 所有 mask 按与逻辑合并（1 保留，0 屏蔽）\n",
    "    m = None\n",
    "    for x in masks:\n",
    "        if x is None:\n",
    "            continue\n",
    "        m = x if m is None else (m & x)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f14fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组网、损失与优化器\n",
    "model = Transformer(src_vocab_size, tgt_vocab_size, d_model, n_head, d_ff, num_layers, dropout).to(device_torch)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "    for src, tgt_inp, tgt_out in make_batch(pairs, batch_size, shuffle=True):\n",
    "        B, S = src.size()\n",
    "        _, T = tgt_inp.size()\n",
    "        src_mask = padding_mask(src)  # (B,1,1,S)\n",
    "        tgt_pad_mask = padding_mask(tgt_inp)  # (B,1,1,T)\n",
    "        tgt_sub_mask = subsequent_mask(T)  # (1,1,T,T)\n",
    "        tgt_mask = combine_masks(tgt_pad_mask, tgt_sub_mask)  # (B,1,T,T)\n",
    "        mem_mask = src_mask  # (B,1,1,S) 广播到 (B,1,T,S)\n",
    "        logits = model(src, tgt_inp, src_mask=src_mask, tgt_mask=tgt_mask, memory_mask=mem_mask)  # (B,T,V)\n",
    "        loss = criterion(logits.view(B*T, -1), tgt_out.view(B*T))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        steps += 1\n",
    "    return total_loss / max(steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88d41ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | loss 5.5394\n",
      "epoch 05 | loss 4.1338\n",
      "epoch 05 | loss 4.1338\n",
      "epoch 10 | loss 3.7267\n",
      "epoch 10 | loss 3.7267\n",
      "epoch 15 | loss 3.4788\n",
      "epoch 15 | loss 3.4788\n",
      "epoch 20 | loss 3.2947\n",
      "epoch 20 | loss 3.2947\n",
      "epoch 25 | loss 3.1506\n",
      "epoch 25 | loss 3.1506\n",
      "epoch 30 | loss 3.0298\n",
      "epoch 30 | loss 3.0298\n"
     ]
    }
   ],
   "source": [
    "# 简单贪心解码\n",
    "@torch.no_grad()\n",
    "def greedy_decode(model, src_sentence: str, max_new_tokens: int = 40):\n",
    "    model.eval()\n",
    "    src = torch.tensor([pad_to_len(encode(tokenize_en(src_sentence), src_stoi, add_bos=False, add_eos=True, max_len=max_len), max_len)], device=device_torch)\n",
    "    src_mask = padding_mask(src)  # (1,1,1,S)\n",
    "    memory = model.encoder(src, src_mask)  # (1,S,C)\n",
    "    ys = torch.tensor([[BOS]], device=device_torch)  # (1,1)\n",
    "    for _ in range(max_new_tokens):\n",
    "        tgt_mask = combine_masks(padding_mask(ys), subsequent_mask(ys.size(1)))  # (1,1,T,T)\n",
    "        out = model.decoder(ys, memory, tgt_mask, src_mask)  # (1,T,C)\n",
    "        logits = model.generator(out[:, -1:, :])  # (1,1,V)\n",
    "        next_token = logits.argmax(dim=-1)[:, -1]  # (1,)\n",
    "        ys = torch.cat([ys, next_token.unsqueeze(1)], dim=1)  # (1,T+1)\n",
    "        if next_token.item() == EOS:\n",
    "            break\n",
    "    pred_ids = ys[0].tolist()[1:]  # 去掉 BOS\n",
    "    pred_tokens = decode(pred_ids, tgt_itos)\n",
    "    return \"\".join(pred_tokens)  # 中文字符级，直接拼接\n",
    "\n",
    "# 训练并测试\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train_one_epoch()\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"epoch {epoch:02d} | loss {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6da9af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是第1条输出：are -> 这是其实。\n",
      "这是第2条输出：hello -> T道了。\n",
      "这是第3条输出：how are you -> 你怎么做？\n",
      "这是第4条输出：see you -> 你看到了。\n",
      "这是第5条输出：what is name -> 这是什么？\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    \"are\",\n",
    "    \"hello\",\n",
    "    \"how are you\",\n",
    "    \"see you\",\n",
    "    \"what is name\",\n",
    " ]\n",
    "for i, s in enumerate(tests, 1):\n",
    "    zh = greedy_decode(model, s)\n",
    "    print(f\"这是第{i}条输出：{s} -> {zh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2933e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xry3py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
